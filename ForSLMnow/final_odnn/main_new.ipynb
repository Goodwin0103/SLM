{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36caacef",
   "metadata": {},
   "source": [
    "## import and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e867b0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All modules imported successfully\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle, Circle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from scipy.io import savemat\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from ODNN_functions import (\n",
    "    create_evaluation_regions,\n",
    "    generate_complex_weights,\n",
    "    generate_fields_ts,\n",
    ")\n",
    "from odnn_generate_label import (\n",
    "    compute_label_centers,\n",
    "    compose_labels_from_patterns,\n",
    "    generate_detector_patterns,\n",
    ")\n",
    "from odnn_io import load_complex_modes_from_mat\n",
    "from odnn_model import D2NNModel\n",
    "from odnn_processing import prepare_sample\n",
    "from odnn_training_eval import (\n",
    "    build_superposition_eval_context,\n",
    "    evaluate_spot_metrics,\n",
    "    format_metric_report,\n",
    "    save_prediction_diagnostics,\n",
    ")\n",
    "from odnn_training_visualization import (\n",
    "    capture_eigenmode_propagation,\n",
    "    save_mode_triptych,\n",
    ")\n",
    "\n",
    "print(\"✓ All modules imported successfully\")\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62facf17",
   "metadata": {},
   "source": [
    "## random seed and device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e612d915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Random seed set to 424242\n",
      "Using Device: CPU\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "SEED = 424242\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "print(f\"✓ Random seed set to {SEED}\")\n",
    "\n",
    "# %%\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:2')\n",
    "    print(f'Using Device: {device}')\n",
    "    print(f'GPU Name: {torch.cuda.get_device_name(device)}')\n",
    "    print(f'GPU Memory: {torch.cuda.get_device_properties(device).total_memory / 1e9:.2f} GB')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('Using Device: CPU')\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaba5f6",
   "metadata": {},
   "source": [
    "## parameter and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6c3cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters configured\n",
      "✓ Storage variables initialized\n",
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "z_layers = 40e-6\n",
    "pixel_size = 1e-6\n",
    "z_prop = 120e-6\n",
    "wavelength = 1568e-9\n",
    "z_input_to_first = 40e-6\n",
    "\n",
    "field_size = 25\n",
    "layer_size = 110\n",
    "num_modes = 6\n",
    "\n",
    "circle_focus_radius = 5\n",
    "circle_detectsize = 10\n",
    "eigenmode_focus_radius = 12.5\n",
    "eigenmode_detectsize = 15\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 1000\n",
    "\n",
    "training_dataset_mode = \"eigenmode\"\n",
    "phase_option = 4\n",
    "\n",
    "evaluation_mode = \"superposition\"\n",
    "num_superposition_eval_samples = 1000\n",
    "superposition_eval_seed = 20240116\n",
    "\n",
    "label_pattern_mode = \"circle\"\n",
    "pred_case = 1\n",
    "\n",
    "show_detection_overlap_debug = True\n",
    "detection_overlap_label_index = 0\n",
    "prop_slices_per_segment = 10\n",
    "prop_output_slices = 10\n",
    "\n",
    "num_layer_option = [2, 3, 4, 5, 6]\n",
    "\n",
    "print(\"Parameters configured\")\n",
    "\n",
    "# %%\n",
    "all_losses = []\n",
    "all_phase_masks = []\n",
    "model_metrics = []\n",
    "all_amplitudes_diff = []\n",
    "all_average_amplitudes_diff = []\n",
    "all_amplitudes_relative_diff = []\n",
    "all_complex_weights_pred = []\n",
    "all_image_data_pred = []\n",
    "all_cc_real = []\n",
    "all_cc_imag = []\n",
    "all_cc_recon_amp = []\n",
    "all_cc_recon_phase = []\n",
    "all_training_summaries = []\n",
    "\n",
    "print(\"✓ Storage variables initialized\")\n",
    "\n",
    "# %%\n",
    "def build_mode_context(base_modes, num_modes):\n",
    "    if base_modes.shape[2] < num_modes:\n",
    "        raise ValueError(\n",
    "            f\"Requested {num_modes} modes, but source file only has {base_modes.shape[2]}.\"\n",
    "        )\n",
    "    \n",
    "    mmf_data = base_modes[:, :, :num_modes].transpose(2, 0, 1)\n",
    "    mmf_data_amp = np.abs(mmf_data)\n",
    "    mmf_data_amp_norm = (mmf_data_amp - mmf_data_amp.min()) / (mmf_data_amp.max() - mmf_data_amp.min())\n",
    "    mmf_data = mmf_data_amp_norm * np.exp(1j * np.angle(mmf_data))\n",
    "\n",
    "    if phase_option in [1, 2, 3, 5]:\n",
    "        base_amplitudes_local, base_phases_local = generate_complex_weights(\n",
    "            1000, num_modes, phase_option\n",
    "        )\n",
    "    elif phase_option == 4:\n",
    "        base_amplitudes_local = np.eye(num_modes, dtype=np.float32)\n",
    "        base_phases_local = np.zeros((num_modes, num_modes), dtype=np.float32)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported phase_option: {phase_option}\")\n",
    "\n",
    "    return {\n",
    "        \"mmf_data_np\": mmf_data,\n",
    "        \"mmf_data_ts\": torch.from_numpy(mmf_data),\n",
    "        \"base_amplitudes\": base_amplitudes_local,\n",
    "        \"base_phases\": base_phases_local,\n",
    "    }\n",
    "\n",
    "\n",
    "def build_uniform_fractions(count):\n",
    "    if count <= 0:\n",
    "        return ()\n",
    "    fractions = np.linspace(1.0 / (count + 1), count / (count + 1), count, dtype=float)\n",
    "    return tuple(float(f) for f in fractions)\n",
    "\n",
    "print(\"✓ Helper functions defined\")\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11aa2a74",
   "metadata": {},
   "source": [
    "## data loading and label generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f00dc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading eigenmode data...\n",
      "✓ Loaded modes shape: (25, 25, 103)\n",
      "  Data type: complex64\n",
      "\n",
      "Building mode context (using 3 modes)...\n",
      "✓ Mode context built\n",
      "  MMF data shape: (3, 25, 25)\n",
      "✓ Eigenmode visualization saved\n",
      "\n",
      "Generating labels...\n",
      "  Using circular patterns...\n",
      "  Layout radius: 5\n",
      "相邻图案边缘间距： 行=50.00, 列=20.00\n",
      "相邻图案中心间距： 行=60.00, 列=30.00\n",
      "中心坐标： [(55, 25), (55, 55), (55, 85)]\n",
      "\n",
      "Detector centers:\n",
      "  Detector 1: (55.0, 25.0)\n",
      "  Detector 2: (55.0, 55.0)\n",
      "  Detector 3: (55.0, 85.0)\n",
      "✓ Label data generated, shape: torch.Size([110, 110, 3])\n",
      "✓ Label visualization saved\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"Loading eigenmode data...\")\n",
    "eigenmodes_OM4 = load_complex_modes_from_mat(\n",
    "    'mmf_103modes_25_PD_1.15.mat',\n",
    "    key='modes_field'\n",
    ")\n",
    "\n",
    "print(f\"✓ Loaded modes shape: {eigenmodes_OM4.shape}\")\n",
    "print(f\"  Data type: {eigenmodes_OM4.dtype}\")\n",
    "\n",
    "# %%\n",
    "print(f\"\\nBuilding mode context (using {num_modes} modes)...\")\n",
    "mode_context = build_mode_context(eigenmodes_OM4, num_modes)\n",
    "\n",
    "MMF_data = mode_context[\"mmf_data_np\"]\n",
    "MMF_data_ts = mode_context[\"mmf_data_ts\"]\n",
    "base_amplitudes = mode_context[\"base_amplitudes\"]\n",
    "base_phases = mode_context[\"base_phases\"]\n",
    "\n",
    "print(f\"✓ Mode context built\")\n",
    "print(f\"  MMF data shape: {MMF_data.shape}\")\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(2, num_modes, figsize=(3*num_modes, 6))\n",
    "\n",
    "for i in range(num_modes):\n",
    "    im_amp = axes[0, i].imshow(np.abs(MMF_data[i]), cmap='hot')\n",
    "    axes[0, i].set_title(f'Mode {i+1} Amplitude')\n",
    "    axes[0, i].axis('off')\n",
    "    plt.colorbar(im_amp, ax=axes[0, i], fraction=0.046)\n",
    "    \n",
    "    im_phase = axes[1, i].imshow(np.angle(MMF_data[i]), cmap='hsv', vmin=-np.pi, vmax=np.pi)\n",
    "    axes[1, i].set_title(f'Mode {i+1} Phase')\n",
    "    axes[1, i].axis('off')\n",
    "    plt.colorbar(im_phase, ax=axes[1, i], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "os.makedirs('results', exist_ok=True)\n",
    "plt.savefig('results/eigenmodes_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Eigenmode visualization saved\")\n",
    "\n",
    "# %%\n",
    "print(\"\\nGenerating labels...\")\n",
    "label_size = layer_size\n",
    "focus_radius = circle_focus_radius\n",
    "detectsize = circle_detectsize\n",
    "\n",
    "if pred_case == 1:\n",
    "    num_detector = num_modes\n",
    "    detector_focus_radius = focus_radius\n",
    "    detector_detectsize = detectsize\n",
    "    \n",
    "    if label_pattern_mode == \"eigenmode\":\n",
    "        print(\"  Using eigenmode patterns...\")\n",
    "        pattern_stack = np.transpose(np.abs(MMF_data), (1, 2, 0))\n",
    "        pattern_h, pattern_w, _ = pattern_stack.shape\n",
    "        if pattern_h > label_size or pattern_w > label_size:\n",
    "            raise ValueError(\n",
    "                f\"Eigenmode pattern size ({pattern_h}x{pattern_w}) exceeds label canvas {label_size}.\"\n",
    "            )\n",
    "        layout_radius = math.ceil(max(pattern_h, pattern_w) / 2)\n",
    "        detector_focus_radius = eigenmode_focus_radius\n",
    "        detector_detectsize = eigenmode_detectsize\n",
    "        \n",
    "    elif label_pattern_mode == \"circle\":\n",
    "        print(\"  Using circular patterns...\")\n",
    "        circle_radius = circle_focus_radius\n",
    "        pattern_size = circle_radius * 2\n",
    "        if pattern_size % 2 == 0:\n",
    "            pattern_size += 1\n",
    "        pattern_stack = generate_detector_patterns(\n",
    "            pattern_size, pattern_size, num_detector, shape=\"circle\"\n",
    "        )\n",
    "        layout_radius = circle_radius\n",
    "        detector_focus_radius = circle_radius\n",
    "        detector_detectsize = circle_detectsize\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown label_pattern_mode: {label_pattern_mode}\")\n",
    "\n",
    "    focus_radius = detector_focus_radius\n",
    "    detectsize = detector_detectsize\n",
    "    \n",
    "    print(f\"  Layout radius: {layout_radius}\")\n",
    "\n",
    "# %%\n",
    "centers, _, _ = compute_label_centers(label_size, label_size, num_detector, layout_radius)\n",
    "\n",
    "print(f\"\\nDetector centers:\")\n",
    "for i, (cx, cy) in enumerate(centers):\n",
    "    print(f\"  Detector {i+1}: ({cx:.1f}, {cy:.1f})\")\n",
    "\n",
    "# %%\n",
    "mode_label_maps = [\n",
    "    compose_labels_from_patterns(\n",
    "        label_size,\n",
    "        label_size,\n",
    "        pattern_stack,\n",
    "        centers,\n",
    "        Index=i + 1,\n",
    "        visualize=False,\n",
    "    )\n",
    "    for i in range(num_detector)\n",
    "]\n",
    "\n",
    "MMF_Label_data = torch.from_numpy(\n",
    "    np.stack(mode_label_maps, axis=2).astype(np.float32)\n",
    ")\n",
    "\n",
    "print(f\"✓ Label data generated, shape: {MMF_Label_data.shape}\")\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(1, num_modes, figsize=(4*num_modes, 4))\n",
    "if num_modes == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i in range(num_modes):\n",
    "    im = axes[i].imshow(mode_label_maps[i], cmap='inferno')\n",
    "    axes[i].set_title(f'Label for Mode {i+1}')\n",
    "    axes[i].axis('off')\n",
    "    plt.colorbar(im, ax=axes[i], fraction=0.046)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/labels_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Label visualization saved\")\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc8ab58",
   "metadata": {},
   "source": [
    "## trainning data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "086fbd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building training dataset (mode: eigenmode)...\n",
      "  Number of training samples: 3\n",
      "✓ Training dataset built\n",
      "  Image data shape: torch.Size([3, 1, 25, 25])\n",
      "  Label data shape: torch.Size([3, 1, 110, 110])\n",
      "✓ Training samples visualization saved\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(f\"\\nBuilding training dataset (mode: {training_dataset_mode})...\")\n",
    "\n",
    "if training_dataset_mode == \"eigenmode\":\n",
    "    if phase_option == 4:\n",
    "        num_train_samples = num_modes\n",
    "        amplitudes = base_amplitudes[:num_train_samples]\n",
    "        phases = base_phases[:num_train_samples]\n",
    "    else:\n",
    "        amplitudes = base_amplitudes\n",
    "        phases = base_phases\n",
    "        num_train_samples = amplitudes.shape[0]\n",
    "\n",
    "    print(f\"  Number of training samples: {num_train_samples}\")\n",
    "    \n",
    "    amplitudes_phases = np.hstack((amplitudes, phases[:, 1:] / (2 * np.pi)))\n",
    "    \n",
    "    label_data = torch.zeros([num_train_samples, 1, layer_size, layer_size])\n",
    "    amplitude_weights = torch.from_numpy(amplitudes_phases[:, 0:num_modes]).float()\n",
    "    energy_weights = amplitude_weights**2\n",
    "    combined_labels = (\n",
    "        energy_weights[:, None, None, :] * MMF_Label_data.unsqueeze(0)\n",
    "    ).sum(dim=3)\n",
    "    label_data[:, 0, :, :] = combined_labels\n",
    "\n",
    "    complex_weights = amplitudes * np.exp(1j * phases)\n",
    "    complex_weights_ts = torch.from_numpy(complex_weights.astype(np.complex64))\n",
    "    image_data = generate_fields_ts(\n",
    "        complex_weights_ts, MMF_data_ts, num_train_samples, num_modes, field_size\n",
    "    ).to(torch.complex64)\n",
    "\n",
    "    train_dataset = [\n",
    "        prepare_sample(image_data[i], label_data[i], layer_size) \n",
    "        for i in range(num_train_samples)\n",
    "    ]\n",
    "    train_tensor_data = TensorDataset(\n",
    "        *[torch.stack(tensors) for tensors in zip(*train_dataset)]\n",
    "    )\n",
    "    \n",
    "elif training_dataset_mode == \"superposition\":\n",
    "    num_train_samples = 100\n",
    "    print(f\"  Number of training samples: {num_train_samples}\")\n",
    "    \n",
    "    super_train_ctx = build_superposition_eval_context(\n",
    "        num_train_samples,\n",
    "        num_modes=num_modes,\n",
    "        field_size=field_size,\n",
    "        layer_size=layer_size,\n",
    "        mmf_modes=MMF_data_ts,\n",
    "        mmf_label_data=MMF_Label_data,\n",
    "        batch_size=batch_size,\n",
    "        second_mode_half_range=True,\n",
    "        rng_seed=20240115,\n",
    "    )\n",
    "    train_dataset = super_train_ctx[\"dataset\"]\n",
    "    train_tensor_data = super_train_ctx[\"tensor_dataset\"]\n",
    "    image_data = super_train_ctx[\"image_data\"]\n",
    "    label_data = train_tensor_data.tensors[1]\n",
    "    amplitudes = super_train_ctx[\"amplitudes\"]\n",
    "    phases = super_train_ctx[\"phases\"]\n",
    "    amplitudes_phases = super_train_ctx[\"amplitudes_phases\"]\n",
    "else:\n",
    "    raise ValueError(f\"Unknown training_dataset_mode: {training_dataset_mode}\")\n",
    "\n",
    "label_test_data = label_data\n",
    "image_test_data = image_data\n",
    "\n",
    "print(f\"✓ Training dataset built\")\n",
    "print(f\"  Image data shape: {image_data.shape}\")\n",
    "print(f\"  Label data shape: {label_data.shape}\")\n",
    "\n",
    "# %%\n",
    "fig, axes = plt.subplots(2, min(3, num_train_samples), figsize=(12, 8))\n",
    "if num_train_samples == 1:\n",
    "    axes = axes.reshape(2, 1)\n",
    "\n",
    "for i in range(min(3, num_train_samples)):\n",
    "    axes[0, i].imshow(np.abs(image_data[i, 0].cpu().numpy()), cmap='hot')\n",
    "    axes[0, i].set_title(f'Sample {i+1} Input')\n",
    "    axes[0, i].axis('off')\n",
    "    \n",
    "    axes[1, i].imshow(label_data[i, 0].cpu().numpy(), cmap='inferno')\n",
    "    axes[1, i].set_title(f'Sample {i+1} Label')\n",
    "    axes[1, i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/training_samples_visualization.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"✓ Training samples visualization saved\")\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5387b2",
   "metadata": {},
   "source": [
    "## Test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a42dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building test dataset (mode: superposition)...\n",
      "  Training batches: 1\n",
      "  Generating 1000 superposition samples...\n",
      "✓ Test dataset built\n",
      "  Test samples: 1000\n",
      "  Test batches: 63\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(f\"\\nBuilding test dataset (mode: {evaluation_mode})...\")\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_tensor_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    generator=g,\n",
    ")\n",
    "\n",
    "print(f\"  Training batches: {len(train_loader)}\")\n",
    "\n",
    "superposition_eval_ctx = None\n",
    "\n",
    "if evaluation_mode == \"eigenmode\":\n",
    "    print(\"  Using eigenmode evaluation...\")\n",
    "    test_dataset = train_dataset\n",
    "    test_tensor_data = train_tensor_data\n",
    "    test_loader = DataLoader(test_tensor_data, batch_size=batch_size, shuffle=False)\n",
    "    eval_amplitudes = amplitudes\n",
    "    eval_amplitudes_phases = amplitudes_phases\n",
    "    eval_phases = phases\n",
    "    image_test_data = image_data\n",
    "    \n",
    "elif evaluation_mode == \"superposition\":\n",
    "    if pred_case != 1:\n",
    "        raise ValueError(\"Superposition evaluation mode currently supports pred_case == 1 only.\")\n",
    "    \n",
    "    print(f\"  Generating {num_superposition_eval_samples} superposition samples...\")\n",
    "    super_ctx = build_superposition_eval_context(\n",
    "        num_superposition_eval_samples,\n",
    "        num_modes=num_modes,\n",
    "        field_size=field_size,\n",
    "        layer_size=layer_size,\n",
    "        mmf_modes=MMF_data_ts,\n",
    "        mmf_label_data=MMF_Label_data,\n",
    "        batch_size=batch_size,\n",
    "        second_mode_half_range=True,\n",
    "        rng_seed=superposition_eval_seed,\n",
    "    )\n",
    "    test_dataset = super_ctx[\"dataset\"]\n",
    "    test_tensor_data = super_ctx[\"tensor_dataset\"]\n",
    "    test_loader = super_ctx[\"loader\"]\n",
    "    image_test_data = super_ctx[\"image_data\"]\n",
    "    eval_amplitudes = super_ctx[\"amplitudes\"]\n",
    "    eval_amplitudes_phases = super_ctx[\"amplitudes_phases\"]\n",
    "    eval_phases = super_ctx[\"phases\"]\n",
    "    superposition_eval_ctx = super_ctx\n",
    "else:\n",
    "    raise ValueError(f\"Unknown evaluation_mode: {evaluation_mode}\")\n",
    "\n",
    "print(f\"✓ Test dataset built\")\n",
    "print(f\"  Test samples: {len(test_dataset)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3e384c",
   "metadata": {},
   "source": [
    "## detector regions generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8c78137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating detection regions...\n",
      "✓ Detection regions generated:\n",
      "  Detector 1: x=[20, 30], y=[50, 60], size=10×10\n",
      "  Detector 2: x=[50, 60], y=[50, 60], size=10×10\n",
      "  Detector 3: x=[80, 90], y=[50, 60], size=10×10\n",
      "\n",
      "Checking detector overlap...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shiyue/.0_code/ForSLMnow/ForSLMnow/final_odnn/ODNN_functions.py:517: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ No overlap detected\n",
      "✔ Debug plot saved -> results/detection_region_debug/detection_overlap_20260205_155543.png\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"\\nGenerating detection regions...\")\n",
    "\n",
    "if pred_case == 1:\n",
    "    evaluation_regions = create_evaluation_regions(\n",
    "        layer_size, layer_size, num_detector, focus_radius, detectsize\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Detection regions generated:\")\n",
    "    for i, (x0, x1, y0, y1) in enumerate(evaluation_regions):\n",
    "        print(f\"  Detector {i+1}: x=[{x0}, {x1}], y=[{y0}, {y1}], size={x1-x0}×{y1-y0}\")\n",
    "\n",
    "# %%\n",
    "if show_detection_overlap_debug:\n",
    "    print(\"\\nChecking detector overlap...\")\n",
    "    \n",
    "    detection_debug_dir = Path(\"results/detection_region_debug\")\n",
    "    detection_debug_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    overlap_map = np.zeros((layer_size, layer_size), dtype=np.float32)\n",
    "    for (x0, x1, y0, y1) in evaluation_regions:\n",
    "        overlap_map[y0:y1, x0:x1] += 1.0\n",
    "    \n",
    "    overlap_pixels = int(np.count_nonzero(overlap_map > 1.0 + 1e-6))\n",
    "    max_overlap = float(overlap_map.max()) if overlap_map.size else 0.0\n",
    "    \n",
    "    label_sample_np = None\n",
    "    if isinstance(label_data, torch.Tensor) and label_data.shape[0] > 0:\n",
    "        sample_idx = min(max(0, detection_overlap_label_index), label_data.shape[0] - 1)\n",
    "        label_sample_np = label_data[sample_idx, 0].detach().cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    if label_sample_np is not None:\n",
    "        im0 = axes[0].imshow(label_sample_np, cmap=\"inferno\")\n",
    "        fig.colorbar(im0, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "        axes[0].set_title(f\"Label sample #{sample_idx + 1} with detectors\")\n",
    "    else:\n",
    "        axes[0].imshow(np.zeros((layer_size, layer_size), dtype=np.float32), cmap=\"Greys\")\n",
    "        axes[0].set_title(\"Detector layout (no label sample)\")\n",
    "    axes[0].set_axis_off()\n",
    "    \n",
    "    circle_radius = focus_radius\n",
    "    for idx_region, (x0, x1, y0, y1) in enumerate(evaluation_regions):\n",
    "        color = plt.cm.tab20(idx_region % 20)\n",
    "        \n",
    "        rect = Rectangle(\n",
    "            (x0, y0), x1 - x0, y1 - y0, \n",
    "            linewidth=1.0, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        axes[0].add_patch(rect)\n",
    "        \n",
    "        center_x = (x0 + x1) / 2.0\n",
    "        center_y = (y0 + y1) / 2.0\n",
    "        circle = Circle(\n",
    "            (center_x, center_y),\n",
    "            radius=circle_radius,\n",
    "            linewidth=1.0,\n",
    "            edgecolor=color,\n",
    "            linestyle=\"--\",\n",
    "            fill=False,\n",
    "        )\n",
    "        axes[0].add_patch(circle)\n",
    "        \n",
    "        axes[0].text(\n",
    "            x0 + 1, y0 + 4,\n",
    "            f\"M{idx_region + 1}\",\n",
    "            color=color,\n",
    "            fontsize=8,\n",
    "            weight=\"bold\",\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"black\", alpha=0.4, edgecolor=\"none\"),\n",
    "        )\n",
    "    \n",
    "    im1 = axes[1].imshow(overlap_map, cmap=\"viridis\")\n",
    "    fig.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    axes[1].set_title(\"Detector coverage count (overlap map)\")\n",
    "    axes[1].set_axis_off()\n",
    "    \n",
    "    overlap_plot_path = detection_debug_dir / f\"detection_overlap_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png\"\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(overlap_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    if overlap_pixels > 0:\n",
    "        print(f\"⚠ Detection regions overlap: {overlap_pixels} pixels\")\n",
    "    else:\n",
    "        print(\"✔ No overlap detected\")\n",
    "    print(f\"✔ Debug plot saved -> {overlap_plot_path}\")\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600342f8",
   "metadata": {},
   "source": [
    "## Trainning loop, evaluation and visiualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "207b6758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Starting model training loop\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Training D2NN with 2 layers\n",
      "============================================================\n",
      "\n",
      "D2NNModel(\n",
      "  (pre_propagation): Propagation()\n",
      "  (layers): ModuleList(\n",
      "    (0): DiffractionLayer()\n",
      "    (1): DiffractionLayer()\n",
      "  )\n",
      "  (propagation): Propagation()\n",
      "  (regression): RegressionDetector()\n",
      ")\n",
      "\n",
      "Model Statistics:\n",
      "  Total parameters: 24,200\n",
      "  Trainable parameters: 24,200\n",
      "\n",
      "Training Configuration:\n",
      "  Loss: MSE, Optimizer: Adam, LR: 1.99, Decay: 0.99\n",
      "\n",
      "Starting training...\n",
      "Epoch    Loss                 Time (s)   LR        \n",
      "--------------------------------------------------\n",
      "1        0.0066927727         0.06       1.970100  \n",
      "100      0.0011214772         0.01       0.728404  \n",
      "200      0.0011037089         0.02       0.266620  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m outputs \u001b[38;5;241m=\u001b[39m D2NN(images)\n\u001b[1;32m     57\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 58\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     61\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Starting model training loop\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for num_layer in num_layer_option:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Training D2NN with {num_layer} layers\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    D2NN = D2NNModel(\n",
    "        num_layers=num_layer,\n",
    "        layer_size=layer_size,\n",
    "        z_layers=z_layers,\n",
    "        z_prop=z_prop,\n",
    "        pixel_size=pixel_size,\n",
    "        wavelength=wavelength,\n",
    "        device=device,\n",
    "        padding_ratio=0.5,\n",
    "        z_input_to_first=z_input_to_first,\n",
    "    ).to(device)\n",
    "    \n",
    "    print(D2NN)\n",
    "    \n",
    "    total_params = sum(p.numel() for p in D2NN.parameters())\n",
    "    trainable_params = sum(p.numel() for p in D2NN.parameters() if p.requires_grad)\n",
    "    print(f\"\\nModel Statistics:\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(D2NN.parameters(), lr=1.99)\n",
    "    scheduler = ExponentialLR(optimizer, gamma=0.99)\n",
    "    \n",
    "    print(f\"\\nTraining Configuration:\")\n",
    "    print(f\"  Loss: MSE, Optimizer: Adam, LR: 1.99, Decay: 0.99\")\n",
    "    \n",
    "    losses = []\n",
    "    epoch_durations = []\n",
    "    training_start_time = time.time()\n",
    "    \n",
    "    print(f\"\\nStarting training...\")\n",
    "    print(f\"{'Epoch':<8} {'Loss':<20} {'Time (s)':<10} {'LR':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        epoch_start_time = time.time()\n",
    "        D2NN.train()\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device, dtype=torch.complex64, non_blocking=True)\n",
    "            labels = labels.to(device, dtype=torch.float32, non_blocking=True)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            outputs = D2NN(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        scheduler.step()\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        losses.append(avg_loss)\n",
    "        \n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.synchronize(device)\n",
    "        epoch_duration = time.time() - epoch_start_time\n",
    "        epoch_durations.append(epoch_duration)\n",
    "        \n",
    "        if epoch % 100 == 0 or epoch == 1 or epoch == epochs:\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            print(f\"{epoch:<8} {avg_loss:<20.10f} {epoch_duration:<10.2f} {current_lr:<10.6f}\")\n",
    "    \n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.synchronize(device)\n",
    "    total_training_time = time.time() - training_start_time\n",
    "    \n",
    "    print(f\"\\n✓ Training completed\")\n",
    "    print(f\"  Total time: {total_training_time:.2f} seconds ({total_training_time / 60:.2f} minutes)\")\n",
    "    print(f\"  Final loss: {losses[-1]:.10f}\")\n",
    "    \n",
    "    all_losses.append(losses)\n",
    "\n",
    "# %%\n",
    "# %%\n",
    "    training_output_dir = Path(\"results/training_analysis\")\n",
    "    training_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    epochs_array = np.arange(1, epochs + 1, dtype=np.int32)\n",
    "    cumulative_epoch_times = np.cumsum(epoch_durations)\n",
    "    timestamp_tag = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.plot(epochs_array, losses, label=\"Training Loss\", linewidth=2)\n",
    "    ax.set_xlabel(\"Epoch\", fontsize=12)\n",
    "    ax.set_ylabel(\"Loss\", fontsize=12)\n",
    "    ax.set_title(f\"D2NN Training Loss ({num_layer} layers)\", fontsize=14)\n",
    "    ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "    ax.legend(fontsize=11)\n",
    "    loss_plot_path = training_output_dir / f\"loss_curve_layers{num_layer}_m{num_modes}_ls{layer_size}_{timestamp_tag}.png\"\n",
    "    fig.savefig(loss_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig_time, ax_time = plt.subplots(figsize=(10, 6))\n",
    "    ax_time.plot(epochs_array, cumulative_epoch_times, label=\"Cumulative Time\", linewidth=2, color='tab:orange')\n",
    "    ax_time.set_xlabel(\"Epoch\", fontsize=12)\n",
    "    ax_time.set_ylabel(\"Time (seconds)\", fontsize=12)\n",
    "    ax_time.set_title(f\"Cumulative Training Time ({num_layer} layers)\", fontsize=14)\n",
    "    ax_time.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "    ax_time.legend(fontsize=11)\n",
    "    time_plot_path = training_output_dir / f\"epoch_time_layers{num_layer}_m{num_modes}_ls{layer_size}_{timestamp_tag}.png\"\n",
    "    fig_time.savefig(time_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig_time)\n",
    "    \n",
    "    mat_path = training_output_dir / f\"training_curves_layers{num_layer}_m{num_modes}_ls{layer_size}_{timestamp_tag}.mat\"\n",
    "    savemat(\n",
    "        str(mat_path),\n",
    "        {\n",
    "            \"epochs\": epochs_array,\n",
    "            \"losses\": np.array(losses, dtype=np.float64),\n",
    "            \"epoch_durations\": np.array(epoch_durations, dtype=np.float64),\n",
    "            \"cumulative_epoch_times\": np.array(cumulative_epoch_times, dtype=np.float64),\n",
    "            \"total_training_time\": np.array([total_training_time], dtype=np.float64),\n",
    "            \"num_layers\": np.array([num_layer], dtype=np.int32),\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✔ Saved training plots and data\")\n",
    "    \n",
    "    print(\"\\nCapturing propagation...\")\n",
    "    propagation_dir = Path(\"results/propagation_slices\")\n",
    "    eigenmode_index = min(2, MMF_data_ts.shape[0] - 1)\n",
    "    layer_fractions = [build_uniform_fractions(prop_slices_per_segment) for _ in range(num_layer)]\n",
    "    output_fractions = build_uniform_fractions(prop_output_slices)\n",
    "    \n",
    "    propagation_summary = capture_eigenmode_propagation(\n",
    "        model=D2NN,\n",
    "        eigenmode_field=MMF_data_ts[eigenmode_index],\n",
    "        mode_index=eigenmode_index,\n",
    "        layer_size=layer_size,\n",
    "        z_input_to_first=z_input_to_first,\n",
    "        z_layers=z_layers,\n",
    "        z_prop=z_prop,\n",
    "        pixel_size=pixel_size,\n",
    "        wavelength=wavelength,\n",
    "        output_dir=propagation_dir,\n",
    "        tag=f\"layers{num_layer}_{timestamp_tag}\",\n",
    "        fractions_between_layers=layer_fractions,\n",
    "        output_fractions=output_fractions,\n",
    "    )\n",
    "    \n",
    "    print(f\"✔ Saved propagation visualization\")\n",
    "    \n",
    "    energies = np.asarray(propagation_summary.get(\"energies\", []), dtype=np.float64)\n",
    "    if energies.size > 0 and energies[0] != 0:\n",
    "        energy_drop_pct = (energies[0] - energies[-1]) / energies[0] * 100.0\n",
    "        print(f\"   Energy drop: {energy_drop_pct:.2f}%\")\n",
    "    \n",
    "    mode_triptych_records = []\n",
    "    \n",
    "    if evaluation_mode == \"eigenmode\":\n",
    "        print(\"\\nSaving mode triptychs...\")\n",
    "        triptych_dir = Path(\"results/mode_triptychs\")\n",
    "        mode_tag = f\"layers{num_layer}_m{num_modes}_{timestamp_tag}\"\n",
    "        \n",
    "        for mode_idx in range(min(num_modes, len(MMF_data_ts))):\n",
    "            label_tensor = label_data[mode_idx, 0]\n",
    "            record = save_mode_triptych(\n",
    "                model=D2NN,\n",
    "                mode_index=mode_idx,\n",
    "                eigenmode_field=MMF_data_ts[mode_idx],\n",
    "                label_field=label_tensor,\n",
    "                layer_size=layer_size,\n",
    "                output_dir=triptych_dir,\n",
    "                tag=mode_tag,\n",
    "                evaluation_regions=evaluation_regions,\n",
    "                detect_radius=detectsize,\n",
    "                show_mask_overlays=True,\n",
    "            )\n",
    "            mode_triptych_records.append(\n",
    "                {\n",
    "                    \"mode\": mode_idx + 1,\n",
    "                    \"fig\": record[\"fig_path\"],\n",
    "                    \"mat\": record[\"mat_path\"],\n",
    "                }\n",
    "            )\n",
    "            print(f\"✔ Saved mode {mode_idx + 1} triptych\")\n",
    "    \n",
    "    all_training_summaries.append(\n",
    "        {\n",
    "            \"num_layers\": num_layer,\n",
    "            \"total_time\": total_training_time,\n",
    "            \"loss_plot\": str(loss_plot_path),\n",
    "            \"time_plot\": str(time_plot_path),\n",
    "            \"mat_path\": str(mat_path),\n",
    "            \"propagation_fig\": propagation_summary[\"fig_path\"],\n",
    "            \"propagation_mat\": propagation_summary[\"mat_path\"],\n",
    "            \"mode_triptychs\": mode_triptych_records,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# %%\n",
    "# %%\n",
    "    print(\"\\nSaving model checkpoint...\")\n",
    "    ckpt_dir = \"checkpoints\"\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)\n",
    "    \n",
    "    ckpt = {\n",
    "        \"state_dict\": D2NN.state_dict(),\n",
    "        \"meta\": {\n",
    "            \"num_layers\": len(D2NN.layers),\n",
    "            \"layer_size\": layer_size,\n",
    "            \"z_layers\": z_layers,\n",
    "            \"z_prop\": z_prop,\n",
    "            \"pixel_size\": pixel_size,\n",
    "            \"wavelength\": wavelength,\n",
    "            \"padding_ratio\": 0.5,\n",
    "            \"field_size\": field_size,\n",
    "            \"num_modes\": num_modes,\n",
    "            \"z_input_to_first\": z_input_to_first,\n",
    "        }\n",
    "    }\n",
    "    save_path = os.path.join(ckpt_dir, f\"odnn_{len(D2NN.layers)}layers_m{num_modes}_ls{layer_size}.pth\")\n",
    "    torch.save(ckpt, save_path)\n",
    "    print(\"✔ Saved model checkpoint\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    phase_masks = []\n",
    "    for layer in D2NN.layers:\n",
    "        phase_np = layer.phase.detach().cpu().numpy()\n",
    "        phase_masks.append(np.remainder(phase_np, 2 * np.pi))\n",
    "    all_phase_masks.append(phase_masks)\n",
    "    \n",
    "    print(\"\\nEvaluating model...\")\n",
    "    metrics = evaluate_spot_metrics(\n",
    "        D2NN,\n",
    "        test_loader,\n",
    "        evaluation_regions,\n",
    "        detect_radius=detectsize,\n",
    "        device=device,\n",
    "        pred_case=pred_case,\n",
    "        num_modes=num_modes,\n",
    "        phase_option=phase_option,\n",
    "        amplitudes=eval_amplitudes,\n",
    "        amplitudes_phases=eval_amplitudes_phases,\n",
    "        phases=eval_phases,\n",
    "        mmf_modes=MMF_data_ts,\n",
    "        field_size=field_size,\n",
    "        image_test_data=image_test_data,\n",
    "    )\n",
    "    \n",
    "    print(\"\\nSaving prediction diagnostics...\")\n",
    "    diag_dir = Path(\"results/prediction_viz\") / f\"main_L{num_layer}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "    diag_paths = save_prediction_diagnostics(\n",
    "        D2NN,\n",
    "        test_dataset,\n",
    "        evaluation_regions=evaluation_regions,\n",
    "        layer_size=layer_size,\n",
    "        detect_radius=detectsize,\n",
    "        num_samples=3,\n",
    "        output_dir=diag_dir,\n",
    "        device=device,\n",
    "        tag=f\"main_L{num_layer}\",\n",
    "    )\n",
    "    if diag_paths:\n",
    "        print(f\"✔ Saved {len(diag_paths)} prediction diagnostics\")\n",
    "    \n",
    "    model_metrics.append(metrics)\n",
    "    all_amplitudes_diff.append(metrics.get(\"amplitudes_diff\", np.array([])))\n",
    "    all_average_amplitudes_diff.append(float(metrics.get(\"avg_amplitudes_diff\", float(\"nan\"))))\n",
    "    all_amplitudes_relative_diff.append(float(metrics.get(\"avg_relative_amp_err\", float(\"nan\"))))\n",
    "    all_complex_weights_pred.append(metrics.get(\"complex_weights_pred\", np.array([])))\n",
    "    all_image_data_pred.append(metrics.get(\"image_data_pred\", np.array([])))\n",
    "    all_cc_recon_amp.append(metrics.get(\"cc_recon_amp\", np.array([])))\n",
    "    all_cc_recon_phase.append(metrics.get(\"cc_recon_phase\", np.array([])))\n",
    "    all_cc_real.append(metrics.get(\"cc_real\", np.array([])))\n",
    "    all_cc_imag.append(metrics.get(\"cc_imag\", np.array([])))\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\n",
    "        format_metric_report(\n",
    "            num_modes=num_modes,\n",
    "            phase_option=phase_option,\n",
    "            pred_case=pred_case,\n",
    "            label=f\"{num_layer} layers\",\n",
    "            metrics=metrics,\n",
    "        )\n",
    "    )\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating performance comparison\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if model_metrics:\n",
    "    metrics_dir = Path(\"results/metrics_analysis\")\n",
    "    metrics_dir.mkdir(parents=True, exist_ok=True)\n",
    "    metrics_tag = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    layer_counts = np.asarray(num_layer_option[:len(model_metrics)], dtype=np.int32)\n",
    "    amp_err = np.asarray(all_average_amplitudes_diff[:len(layer_counts)], dtype=np.float64)\n",
    "    amp_err_rel = np.asarray(all_amplitudes_relative_diff[:len(layer_counts)], dtype=np.float64)\n",
    "    \n",
    "    cc_amp_mean_list = []\n",
    "    cc_amp_std_list = []\n",
    "    for cc_arr in all_cc_recon_amp[:len(layer_counts)]:\n",
    "        cc_np = np.asarray(cc_arr, dtype=np.float64)\n",
    "        if cc_np.size:\n",
    "            cc_amp_mean_list.append(float(np.nanmean(cc_np)))\n",
    "            cc_amp_std_list.append(float(np.nanstd(cc_np)))\n",
    "        else:\n",
    "            cc_amp_mean_list.append(float(\"nan\"))\n",
    "            cc_amp_std_list.append(float(\"nan\"))\n",
    "    cc_amp_mean = np.asarray(cc_amp_mean_list, dtype=np.float64)\n",
    "    cc_amp_std = np.asarray(cc_amp_std_list, dtype=np.float64)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 1, figsize=(10, 12), sharex=True)\n",
    "    \n",
    "    axes[0].plot(layer_counts, amp_err, marker=\"o\", linewidth=2, markersize=8)\n",
    "    axes[0].set_ylabel(\"Average Amplitude Error\", fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3, linestyle='--')\n",
    "    axes[0].set_title(\"Performance Metrics vs. Number of Layers\", fontsize=14, pad=20)\n",
    "    \n",
    "    axes[1].plot(layer_counts, amp_err_rel, marker=\"o\", color=\"tab:orange\", linewidth=2, markersize=8)\n",
    "    axes[1].set_ylabel(\"Average Relative Error\", fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    axes[2].errorbar(\n",
    "        layer_counts,\n",
    "        cc_amp_mean,\n",
    "        yerr=cc_amp_std,\n",
    "        marker=\"o\",\n",
    "        color=\"tab:green\",\n",
    "        ecolor=\"tab:green\",\n",
    "        capsize=5,\n",
    "        linewidth=2,\n",
    "        markersize=8,\n",
    "    )\n",
    "    axes[2].set_xlabel(\"Number of Layers\", fontsize=12)\n",
    "    axes[2].set_ylabel(\"Correlation Coefficient\\n(mean ± std)\", fontsize=12)\n",
    "    axes[2].grid(True, alpha=0.3, linestyle='--')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    metrics_plot_path = metrics_dir / f\"metrics_vs_layers_{metrics_tag}.png\"\n",
    "    fig.savefig(metrics_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    \n",
    "    metrics_mat_path = metrics_dir / f\"metrics_vs_layers_{metrics_tag}.mat\"\n",
    "    savemat(\n",
    "        str(metrics_mat_path),\n",
    "        {\n",
    "            \"layers\": layer_counts.astype(np.float64),\n",
    "            \"avg_amp_error\": amp_err,\n",
    "            \"avg_relative_amp_error\": amp_err_rel,\n",
    "            \"cc_amp_mean\": cc_amp_mean,\n",
    "            \"cc_amp_std\": cc_amp_std,\n",
    "        },\n",
    "    )\n",
    "    \n",
    "    print(f\"✔ Metrics comparison saved\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Performance Summary Table\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Layers':<8} {'Amp Error':<15} {'Rel Error':<15} {'CC Mean':<15}\")\n",
    "    print(\"-\"*60)\n",
    "    for i, n_layer in enumerate(layer_counts):\n",
    "        print(f\"{n_layer:<8} {amp_err[i]:<15.6f} {amp_err_rel[i]:<15.6f} {cc_amp_mean[i]:<15.6f}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "# %%\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Summary\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for i, summary in enumerate(all_training_summaries):\n",
    "    print(f\"Model {i+1}: {summary['num_layers']} layers\")\n",
    "    print(f\"  Time: {summary['total_time']:.2f}s ({summary['total_time']/60:.2f}min)\")\n",
    "    if summary['mode_triptychs']:\n",
    "        print(f\"  Triptychs: {len(summary['mode_triptychs'])} saved\")\n",
    "    print()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"All training completed successfully!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# %%\n",
    "def visualize_phase_masks(all_phase_masks, num_layer_option):\n",
    "    for model_idx, phase_masks in enumerate(all_phase_masks):\n",
    "        n_layers = len(phase_masks)\n",
    "        fig, axes = plt.subplots(1, n_layers, figsize=(4*n_layers, 4))\n",
    "        if n_layers == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        for layer_idx, phase in enumerate(phase_masks):\n",
    "            im = axes[layer_idx].imshow(phase, cmap='hsv', vmin=0, vmax=2*np.pi)\n",
    "            axes[layer_idx].set_title(f'Layer {layer_idx+1}')\n",
    "            axes[layer_idx].axis('off')\n",
    "            plt.colorbar(im, ax=axes[layer_idx], fraction=0.046, label='Phase (rad)')\n",
    "        \n",
    "        fig.suptitle(f'Phase Masks - {num_layer_option[model_idx]} Layers', fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'results/phase_masks_{num_layer_option[model_idx]}layers.png', dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"✓ Saved phase masks for {num_layer_option[model_idx]}-layer model\")\n",
    "\n",
    "if all_phase_masks:\n",
    "    visualize_phase_masks(all_phase_masks, num_layer_option[:len(all_phase_masks)])\n",
    "\n",
    "# %%\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "odnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
